{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tribal-solution",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(clf, X, y, param_grid, scoring=\"roc_auc\"):    \n",
    "    search = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=10, scoring=scoring)\n",
    "    search_result = search.fit(X, y)\n",
    "\n",
    "    print(\"Best: %f using %s\" % (search_result.best_score_, search_result.best_params_))\n",
    "    means = search_result.cv_results_['mean_test_score']\n",
    "    stds = search_result.cv_results_['std_test_score']\n",
    "    params = search_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-vitamin",
   "metadata": {},
   "source": [
    "**Select the number of trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier__n_estimators': [50, 100, 250, 500, 750, 1000, 3000]}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier()\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier__n_estimators': [150, 200, 250, 300, 350, 400, 450]}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier()\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-porter",
   "metadata": {},
   "source": [
    "**Tree specific parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier__max_depth':range(3,16,2)}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier(n_estimators=200)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-decline",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'classifier__min_samples_split':range(5,101,5), \n",
    "              'classifier__min_samples_leaf':range(5,101,5)}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier(n_estimators=200, max_depth=3)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-decline",
   "metadata": {},
   "source": [
    "**Subsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"classifier__subsample\": [0.5, 0.75, 1.0]}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.09)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-november",
   "metadata": {},
   "source": [
    "**Max depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"classifier__max_depth\": np.linspace(1, 10, 10)}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.09, subsample=0.75)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-clerk",
   "metadata": {},
   "source": [
    "**Fine tune the learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"classifier__learning_rate\": np.linspace(2/200, 20/200, 10)}\n",
    "\n",
    "preprocessor = utils.define_preprocessor(X_train.columns)\n",
    "clf = GradientBoostingClassifier(n_estimators=200)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "grid_search_cv(pipe, X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DictDist():\n",
    "#     def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "#     def rvs(self, n):\n",
    "#         a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "#         out = []\n",
    "#         for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "#         return out\n",
    "    \n",
    "# class Choice():\n",
    "#     def __init__(self, options): self.options = options\n",
    "#     def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 15\n",
    "# SEED = 1443\n",
    "# RF_dist = DictDist({\n",
    "#     'n_estimators': ss.randint(50, 500),\n",
    "#     'max_depth': ss.randint(2, 10),\n",
    "#     'min_samples_split': ss.randint(2, 75),\n",
    "#     'min_samples_leaf': ss.randint(1, 50),\n",
    "# })\n",
    "# np.random.seed(SEED)\n",
    "# RF_hyperparams_list = RF_dist.rvs(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-ecuador",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
